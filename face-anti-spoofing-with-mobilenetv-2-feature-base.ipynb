{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2289782,"sourceType":"datasetVersion","datasetId":1371510},{"sourceId":57820,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":48481},{"sourceId":57950,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":48481}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport copy\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import softmax\nimport torch.nn.functional as F\nfrom torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, \\\n    AdaptiveAvgPool2d, Sequential, Module\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models import mobilenet_v2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:51:35.679651Z","iopub.execute_input":"2024-07-06T16:51:35.680495Z","iopub.status.idle":"2024-07-06T16:51:39.793958Z","shell.execute_reply.started":"2024-07-06T16:51:35.680457Z","shell.execute_reply":"2024-07-06T16:51:39.792962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data and dataloader","metadata":{}},{"cell_type":"code","source":"# Function to extract face with OpenCV\ndef extract_face(image_path, show=False):\n    image = Image.open(image_path)\n    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n    \n    bbox_file = image_path[:-4] + '_BB.txt'\n    if os.path.exists(bbox_file):\n        bbox = open(bbox_file).readlines()[0]\n        bbox = [int(_) for _ in bbox.strip().split()[:4]]\n        real_w, real_h = image.size\n        x1 = int(bbox[0] * (real_w / 224))\n        y1 = int(bbox[1] * (real_h / 224))\n        w1 = int(bbox[2] * (real_w / 224))\n        h1 = int(bbox[3] * (real_h / 224))\n    else:\n        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n        if len(faces) == 0:\n            raise ValueError(\"No face detected in the image.\")\n        x1, y1, w1, h1 = faces[0]\n\n    face = image.crop((x1, y1, x1 + w1, y1 + h1))\n    if show:\n        plt.imshow(face)\n        plt.show()\n    return face","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:02.956157Z","iopub.execute_input":"2024-07-06T16:52:02.956522Z","iopub.status.idle":"2024-07-06T16:52:02.966336Z","shell.execute_reply.started":"2024-07-06T16:52:02.956492Z","shell.execute_reply":"2024-07-06T16:52:02.965319Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/'\ntrain_size = len(os.listdir(os.path.join(data_dir, 'train')))\ntest_size = len(os.listdir(os.path.join(data_dir, 'test')))\n\nprint('train: {}; test: {}'.format(train_size, test_size))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:06.441847Z","iopub.execute_input":"2024-07-06T16:52:06.442498Z","iopub.status.idle":"2024-07-06T16:52:06.457099Z","shell.execute_reply.started":"2024-07-06T16:52:06.442464Z","shell.execute_reply":"2024-07-06T16:52:06.456176Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train: 8192; test: 1004\n","output_type":"stream"}]},{"cell_type":"code","source":"path_train_json = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/metas/intra_test/train_label.json'\npath_test_json = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/metas/intra_test/test_label.json'\npath_local = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/'","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:08.400918Z","iopub.execute_input":"2024-07-06T16:52:08.401752Z","iopub.status.idle":"2024-07-06T16:52:08.406241Z","shell.execute_reply.started":"2024-07-06T16:52:08.401720Z","shell.execute_reply":"2024-07-06T16:52:08.405004Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_json(path_train_json, orient='index')\ndf_test = pd.read_json(path_test_json, orient='index')\n\ndf_train = df_train.reset_index()\ndf_test = df_test.reset_index()\ndf_train.rename(columns={'index': 'Filepath'}, inplace=True)\ndf_test.rename(columns={'index': 'Filepath'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:10.464165Z","iopub.execute_input":"2024-07-06T16:52:10.464529Z","iopub.status.idle":"2024-07-06T16:52:25.467180Z","shell.execute_reply.started":"2024-07-06T16:52:10.464500Z","shell.execute_reply":"2024-07-06T16:52:25.466405Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train['Filepath'] = df_train['Filepath'].apply(lambda x: path_local +  x)\ndf_test['Filepath'] = df_test['Filepath'].apply(lambda x: path_local  + x)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:25.468741Z","iopub.execute_input":"2024-07-06T16:52:25.469008Z","iopub.status.idle":"2024-07-06T16:52:25.676740Z","shell.execute_reply.started":"2024-07-06T16:52:25.468985Z","shell.execute_reply":"2024-07-06T16:52:25.675675Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"invalid_file_name = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/train/3329/spoof/004046.jpg'\n\ndf_train.drop(df_train[df_train['Filepath']==invalid_file_name].index, inplace=True)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:25.677955Z","iopub.execute_input":"2024-07-06T16:52:25.678260Z","iopub.status.idle":"2024-07-06T16:52:26.053071Z","shell.execute_reply.started":"2024-07-06T16:52:25.678235Z","shell.execute_reply":"2024-07-06T16:52:26.052117Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 Filepath  0  1  2  3  4  5  \\\n0       /kaggle/input/celeba-spoof-for-face-antispoofi...  0  1  1  0  0  0   \n1       /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n2       /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n3       /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n4       /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n...                                                   ... .. .. .. .. .. ..   \n494400  /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n494401  /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n494402  /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  1   \n494403  /kaggle/input/celeba-spoof-for-face-antispoofi...  0  0  0  0  0  0   \n494404  /kaggle/input/celeba-spoof-for-face-antispoofi...  0  1  1  0  0  0   \n\n        6  7  8  ...  34  35  36  37  38  39  40  41  42  43  \n0       0  0  0  ...   0   0   1   0   0   1   0   0   0   0  \n1       0  0  0  ...   0   0   0   0   0   0   6   1   1   1  \n2       0  0  0  ...   0   0   0   0   0   0   7   1   1   1  \n3       0  0  0  ...   0   0   0   0   0   0   5   1   2   1  \n4       0  0  0  ...   0   0   0   0   0   0   7   4   2   1  \n...    .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n494400  0  0  0  ...   0   0   0   0   0   0   3   1   1   1  \n494401  0  0  0  ...   0   0   0   0   0   0   3   3   2   1  \n494402  1  0  0  ...   0   0   1   1   0   0   0   0   0   0  \n494403  0  0  0  ...   0   0   0   0   0   0   7   2   2   1  \n494404  0  0  0  ...   0   0   1   0   0   1   0   0   0   0  \n\n[494404 rows x 45 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>494400</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>494401</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>494402</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>494403</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>494404</th>\n      <td>/kaggle/input/celeba-spoof-for-face-antispoofi...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>494404 rows × 45 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport numpy as np \nfrom skimage.feature import local_binary_pattern\nimport matplotlib.pyplot as plt\n\n\ndef extract_lbp_features(ImagePath):\n    \n    image = cv2.resize(cv2.cvtColor(ImagePath , cv2.COLOR_BGR2GRAY) , (255 , 255))\n    # Compute the Local Binary Pattern (LBP)\n    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n    \n    return np.expand_dims(lbp , axis = 2)\n\n\ndef extract_fourier_features(ImagePath):\n\n    image = cv2.resize(cv2.cvtColor(ImagePath , cv2.COLOR_BGR2GRAY) , (255 , 255))\n     # Compute the 2D Fast Fourier Transform (FFT)\n    f = np.fft.fft2(image)\n    \n    # Shift the zero frequency component to the center\n    fshift = np.fft.fftshift(f)\n    \n    # Compute the magnitude spectrum\n    magnitude_spectrum = np.abs(fshift)\n    \n    # Normalize the magnitude spectrum\n    magnitude_spectrum = np.log(1 + magnitude_spectrum)  # Use log scaling for better visualization\n    \n    \n    return np.expand_dims(magnitude_spectrum , axis = 2)\n\n\ndef extract_hsv_features(ImagePath, bins=8):  \n\n    \n    image = cv2.resize(ImagePath , (255 , 255))\n    # Convert the image to HSV color space\n    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    \n    return hsv_image\n\n\ndef extract_features(ImagePath):\n\n    ImagePath = np.array(ImagePath)\n    lbp = extract_lbp_features(ImagePath)\n    fourier = extract_fourier_features(ImagePath)\n    hsv = extract_hsv_features(ImagePath)\n\n    return np.concatenate((lbp , fourier , hsv) , axis = 2)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:59:57.422658Z","iopub.execute_input":"2024-07-06T16:59:57.423064Z","iopub.status.idle":"2024-07-06T16:59:57.433483Z","shell.execute_reply.started":"2024-07-06T16:59:57.423034Z","shell.execute_reply":"2024-07-06T16:59:57.432385Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# transformations\ntransforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n#         transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n        )\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# down sample the size of trainning set\ndf_train_sample = df_train.sample(frac=0.01, random_state=43)\ndf_train_sample[43].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:40.842257Z","iopub.execute_input":"2024-07-06T16:52:40.843178Z","iopub.status.idle":"2024-07-06T16:52:40.867261Z","shell.execute_reply.started":"2024-07-06T16:52:40.843144Z","shell.execute_reply":"2024-07-06T16:52:40.866410Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"43\n1    3329\n0    1615\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_1 = df_train_sample[df_train_sample[43]==1][:1000]\ndf_2 = df_train_sample[df_train_sample[43]==0][:1000]\ndf_train_sample_balanced = pd.concat([df_1, df_2])\ndf_train_sample_balanced = df_train_sample_balanced.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:42.375142Z","iopub.execute_input":"2024-07-06T16:52:42.376014Z","iopub.status.idle":"2024-07-06T16:52:42.388044Z","shell.execute_reply.started":"2024-07-06T16:52:42.375980Z","shell.execute_reply":"2024-07-06T16:52:42.387007Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# prepare data\nclass FASDataset(Dataset):\n    def __init__(self, df, transforms=None, ft_width=32, ft_height=32):\n        self.df = df\n        self.transforms = transforms\n        self.ft_width = ft_width\n        self.ft_height = ft_height\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx]['Filepath']\n        bbox_path = img_path[:-4] + '_BB.txt'\n        \n        face = extract_face(img_path)\n        sample = np.transpose(extract_features(face) , (2 , 1 , 0))\n        target = df_train.iloc[idx][43]\n                \n        # Generate the FT picture of the sample\n        ft_sample = self.generate_FT(face)\n        \n        if self.transforms is not None:\n            try:\n                sample = self.transforms(face)\n                sample = np.transpose(extract_features(sample) , (2 , 1 , 0))\n            except Exception as err:\n                print('Error Occured: %s' % err, img_path)\n        \n        assert sample is not None\n\n        ft_sample = cv2.resize(ft_sample, (self.ft_width, self.ft_height))\n        ft_sample = torch.from_numpy(ft_sample).float()\n        ft_sample = torch.unsqueeze(ft_sample, 0)\n\n        return sample, ft_sample, target\n    \n    def generate_FT(self, image):\n        image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n        f = np.fft.fft2(image)\n        fshift = np.fft.fftshift(f)\n        fimg = np.log(np.abs(fshift)+1)\n        maxx = -1\n        minn = 100000\n        for i in range(len(fimg)):\n            if maxx < max(fimg[i]):\n                maxx = max(fimg[i])\n            if minn > min(fimg[i]):\n                minn = min(fimg[i])\n        fimg = (fimg - minn+1) / (maxx - minn+1)\n        return fimg","metadata":{"execution":{"iopub.status.busy":"2024-07-06T17:01:01.410975Z","iopub.execute_input":"2024-07-06T17:01:01.411823Z","iopub.status.idle":"2024-07-06T17:01:01.424098Z","shell.execute_reply.started":"2024-07-06T17:01:01.411790Z","shell.execute_reply":"2024-07-06T17:01:01.423113Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ntrain_df, val_df = train_test_split(df_train_sample_balanced, test_size=0.2, random_state=42, stratify=df_train_sample_balanced[43])","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:49.243511Z","iopub.execute_input":"2024-07-06T16:52:49.243884Z","iopub.status.idle":"2024-07-06T16:52:49.253457Z","shell.execute_reply.started":"2024-07-06T16:52:49.243854Z","shell.execute_reply":"2024-07-06T16:52:49.252582Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = FASDataset(train_df)\ndataloader_train = DataLoader(train_dataset, batch_size=32)\n\nval_dataset = FASDataset(val_df)\ndataloader_val = DataLoader(val_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T17:01:08.842605Z","iopub.execute_input":"2024-07-06T17:01:08.843331Z","iopub.status.idle":"2024-07-06T17:01:08.848282Z","shell.execute_reply.started":"2024-07-06T17:01:08.843299Z","shell.execute_reply":"2024-07-06T17:01:08.847320Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('using \\'{}\\' device'.format(device))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:53.695341Z","iopub.execute_input":"2024-07-06T16:52:53.695715Z","iopub.status.idle":"2024-07-06T16:52:53.755900Z","shell.execute_reply.started":"2024-07-06T16:52:53.695685Z","shell.execute_reply":"2024-07-06T16:52:53.754947Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"using 'cuda' device\n","output_type":"stream"}]},{"cell_type":"code","source":"keep_dict = {'1.8M': [32, 32, 103, 103, 64, 13, 13, 64, 26, 26,\n                      64, 13, 13, 64, 52, 52, 64, 231, 231, 128,\n                      154, 154, 128, 52, 52, 128, 26, 26, 128, 52,\n                      52, 128, 26, 26, 128, 26, 26, 128, 308, 308,\n                      128, 26, 26, 128, 26, 26, 128, 512, 512],\n\n             '1.8M_': [32, 32, 103, 103, 64, 13, 13, 64, 13, 13, 64, 13,\n                       13, 64, 13, 13, 64, 231, 231, 128, 231, 231, 128, 52,\n                       52, 128, 26, 26, 128, 77, 77, 128, 26, 26, 128, 26, 26,\n                       128, 308, 308, 128, 26, 26, 128, 26, 26, 128, 512, 512]\n             }\n\nclass Conv_block(Module):\n    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n        super(Conv_block, self).__init__()\n        self.conv = Conv2d(in_c, out_c, kernel_size=kernel, groups=groups,\n                           stride=stride, padding=padding, bias=False)\n        self.bn = BatchNorm2d(out_c)\n        self.prelu = PReLU(out_c)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.prelu(x)\n        return x\n    \nclass Linear_block(Module):\n    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n        super(Linear_block, self).__init__()\n        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel,\n                           groups=groups, stride=stride, padding=padding, bias=False)\n        self.bn = BatchNorm2d(out_c)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return x\n\n\nclass Depth_Wise(Module):\n     def __init__(self, c1, c2, c3, residual=False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n        super(Depth_Wise, self).__init__()\n        c1_in, c1_out = c1\n        c2_in, c2_out = c2\n        c3_in, c3_out = c3\n        self.conv = Conv_block(c1_in, out_c=c1_out, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n        self.conv_dw = Conv_block(c2_in, c2_out, groups=c2_in, kernel=kernel, padding=padding, stride=stride)\n        self.project = Linear_block(c3_in, c3_out, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n        self.residual = residual\n\n     def forward(self, x):\n        if self.residual:\n            short_cut = x\n        x = self.conv(x)\n        x = self.conv_dw(x)\n        x = self.project(x)\n        if self.residual:\n            output = short_cut + x\n        else:\n            output = x\n        return output\n    \n\nclass Residual(Module):\n    def __init__(self, c1, c2, c3, num_block, groups, kernel=(3, 3), stride=(1, 1), padding=(1, 1)):\n        super(Residual, self).__init__()\n        modules = []\n        for i in range(num_block):\n            c1_tuple = c1[i]\n            c2_tuple = c2[i]\n            c3_tuple = c3[i]\n            modules.append(Depth_Wise(c1_tuple, c2_tuple, c3_tuple, residual=True,\n                                      kernel=kernel, padding=padding, stride=stride, groups=groups))\n        self.model = Sequential(*modules)\n\n    def forward(self, x):\n        return self.model(x)\n    \n\n# Define the Fourier Transform Generator\nclass FTGenerator(nn.Module):\n    def __init__(self, in_channels=128, out_channels=1):\n        super(FTGenerator, self).__init__()\n\n        self.ft = nn.Sequential(\n            nn.Conv2d(in_channels, 128, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 64, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, out_channels, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.ft(x)\n\n# Modify the MobileNetV2 model\nclass MobileNetV2_FT(nn.Module):\n    def __init__(self, num_classes=2, freeze_backbone=True):\n        super(MobileNetV2_FT, self).__init__()\n        keep = keep_dict['1.8M_']\n        self.conv1 = Conv_block(5, keep[0], kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n        self.conv2_dw = Conv_block(keep[0], keep[1], kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=keep[1])\n\n        c1 = [(keep[1], keep[2])]\n        c2 = [(keep[2], keep[3])]\n        c3 = [(keep[3], keep[4])]\n\n        self.conv_23 = Depth_Wise(c1[0], c2[0], c3[0], kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=keep[3])\n\n        c1 = [(keep[4], keep[5]), (keep[7], keep[8]), (keep[10], keep[11]), (keep[13], keep[14])]\n        c2 = [(keep[5], keep[6]), (keep[8], keep[9]), (keep[11], keep[12]), (keep[14], keep[15])]\n        c3 = [(keep[6], keep[7]), (keep[9], keep[10]), (keep[12], keep[13]), (keep[15], keep[16])]\n\n        self.conv_3 = Residual(c1, c2, c3, num_block=4, groups=keep[4], kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n\n        c1 = [(keep[16], keep[17])]\n        c2 = [(keep[17], keep[18])]\n        c3 = [(keep[18], keep[19])]\n\n        self.conv_34 = Depth_Wise(c1[0], c2[0], c3[0], kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=keep[19])\n\n        c1 = [(keep[19], keep[20]), (keep[22], keep[23]), (keep[25], keep[26]), (keep[28], keep[29]),\n              (keep[31], keep[32]), (keep[34], keep[35])]\n        c2 = [(keep[20], keep[21]), (keep[23], keep[24]), (keep[26], keep[27]), (keep[29], keep[30]),\n              (keep[32], keep[33]), (keep[35], keep[36])]\n        c3 = [(keep[21], keep[22]), (keep[24], keep[25]), (keep[27], keep[28]), (keep[30], keep[31]),\n              (keep[33], keep[34]), (keep[36], keep[37])]\n\n        self.conv_4 = Residual(c1, c2, c3, num_block=6, groups=keep[19], kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.model = mobilenet_v2(pretrained=True)\n        original_conv = self.model.features[0][0]\n        new_conv = nn.Conv2d(5, original_conv.out_channels, kernel_size=original_conv.kernel_size,\n                             stride=original_conv.stride, padding=original_conv.padding, bias=original_conv.bias)\n\n        # Copy the weights from the original conv layer to the new conv layer\n        with torch.no_grad():\n            new_conv.weight[:, :3, :, :] = original_conv.weight\n            new_conv.weight[:, 3:, :, :] = original_conv.weight.mean(dim=1, keepdim=True)\n\n        # Replace the original conv layer with the new conv layer in the model\n        self.model.features[0][0] = new_conv\n        \n        # Freeze the backbone layers\n        if freeze_backbone:\n            for param in self.model.parameters():\n                param.requires_grad = False\n                \n        # Unfreeze the last two layers\n        for param in self.model.features[-2:].parameters():\n            param.requires_grad = True\n                \n        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n        self.FTGenerator = FTGenerator(in_channels=128)\n\n    def forward(self, x):\n        features = self.model.features(x)\n        # x1 = self.model.avgpool(x)\n        # Global average pooling\n        x1 = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n        x1 = torch.flatten(x1, 1)\n        cls_output = self.model.classifier(x1)\n        \n        if self.training:\n            x = self.conv1(x)\n            x = self.conv2_dw(x)\n            x = self.conv_23(x)\n            x = self.conv_3(x)\n            x = self.conv_34(x)\n            x = self.conv_4(x)\n            ft_output = self.FTGenerator(x)\n            return cls_output , ft_output\n        else:\n            return cls_output","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:52:56.225079Z","iopub.execute_input":"2024-07-06T16:52:56.225408Z","iopub.status.idle":"2024-07-06T16:52:56.270104Z","shell.execute_reply.started":"2024-07-06T16:52:56.225382Z","shell.execute_reply":"2024-07-06T16:52:56.269002Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = MobileNetV2_FT(num_classes=2).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:53:01.270608Z","iopub.execute_input":"2024-07-06T16:53:01.270973Z","iopub.status.idle":"2024-07-06T16:53:01.554797Z","shell.execute_reply.started":"2024-07-06T16:53:01.270943Z","shell.execute_reply":"2024-07-06T16:53:01.553743Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"MobileNetV2_FT(\n  (conv1): Conv_block(\n    (conv): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (prelu): PReLU(num_parameters=32)\n  )\n  (conv2_dw): Conv_block(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (prelu): PReLU(num_parameters=32)\n  )\n  (conv_23): Depth_Wise(\n    (conv): Conv_block(\n      (conv): Conv2d(32, 103, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=103)\n    )\n    (conv_dw): Conv_block(\n      (conv): Conv2d(103, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=103, bias=False)\n      (bn): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=103)\n    )\n    (project): Linear_block(\n      (conv): Conv2d(103, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (conv_3): Residual(\n    (model): Sequential(\n      (0): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (conv_34): Depth_Wise(\n    (conv): Conv_block(\n      (conv): Conv2d(64, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=231)\n    )\n    (conv_dw): Conv_block(\n      (conv): Conv2d(231, 231, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=231, bias=False)\n      (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=231)\n    )\n    (project): Linear_block(\n      (conv): Conv2d(231, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (conv_4): Residual(\n    (model): Sequential(\n      (0): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=231)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(231, 231, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=231, bias=False)\n          (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=231)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(231, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=52)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=52, bias=False)\n          (bn): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=52)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(52, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 77, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=77)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(77, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=77, bias=False)\n          (bn): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=77)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (model): MobileNetV2(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): Conv2dNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n      (0): Dropout(p=0.2, inplace=False)\n      (1): Linear(in_features=1280, out_features=2, bias=True)\n    )\n  )\n  (FTGenerator): FTGenerator(\n    (ft): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:53:08.275320Z","iopub.execute_input":"2024-07-06T16:53:08.276304Z","iopub.status.idle":"2024-07-06T16:53:08.294764Z","shell.execute_reply.started":"2024-07-06T16:53:08.276265Z","shell.execute_reply":"2024-07-06T16:53:08.293923Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"MobileNetV2_FT(\n  (conv1): Conv_block(\n    (conv): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (prelu): PReLU(num_parameters=32)\n  )\n  (conv2_dw): Conv_block(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (prelu): PReLU(num_parameters=32)\n  )\n  (conv_23): Depth_Wise(\n    (conv): Conv_block(\n      (conv): Conv2d(32, 103, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=103)\n    )\n    (conv_dw): Conv_block(\n      (conv): Conv2d(103, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=103, bias=False)\n      (bn): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=103)\n    )\n    (project): Linear_block(\n      (conv): Conv2d(103, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (conv_3): Residual(\n    (model): Sequential(\n      (0): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n          (bn): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=13)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (conv_34): Depth_Wise(\n    (conv): Conv_block(\n      (conv): Conv2d(64, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=231)\n    )\n    (conv_dw): Conv_block(\n      (conv): Conv2d(231, 231, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=231, bias=False)\n      (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (prelu): PReLU(num_parameters=231)\n    )\n    (project): Linear_block(\n      (conv): Conv2d(231, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (conv_4): Residual(\n    (model): Sequential(\n      (0): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=231)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(231, 231, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=231, bias=False)\n          (bn): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=231)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(231, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=52)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=52, bias=False)\n          (bn): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=52)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(52, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 77, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=77)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(77, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=77, bias=False)\n          (bn): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=77)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): Depth_Wise(\n        (conv): Conv_block(\n          (conv): Conv2d(128, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (conv_dw): Conv_block(\n          (conv): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n          (bn): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (prelu): PReLU(num_parameters=26)\n        )\n        (project): Linear_block(\n          (conv): Conv2d(26, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (model): MobileNetV2(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): Conv2dNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n      (0): Dropout(p=0.2, inplace=False)\n      (1): Linear(in_features=1280, out_features=2, bias=True)\n    )\n  )\n  (FTGenerator): FTGenerator(\n    (ft): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize loss functions, and optimizer\ncriterion_cls = nn.CrossEntropyLoss()\ncriterion_ft = nn.MSELoss()\n# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\noptimizer = optim.AdamW(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:53:44.523108Z","iopub.execute_input":"2024-07-06T16:53:44.523859Z","iopub.status.idle":"2024-07-06T16:53:44.531062Z","shell.execute_reply.started":"2024-07-06T16:53:44.523818Z","shell.execute_reply":"2024-07-06T16:53:44.530094Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Function to save the checkpoint\ndef save_checkpoint(model, optimizer, epoch, path, loss):\n    state = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n    }\n    torch.save(state, path)\n\n# Function to load the checkpoint\ndef load_checkpoint(model, optimizer, path, device):\n    checkpoint = torch.load(path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    return model, optimizer, epoch, loss\n\n\n# Function to evaluate model on validation data\ndef evaluate_model(model, dataloader, criterion_cls, device):\n    model.eval()\n    running_loss = 0.0\n    running_acc = 0.0\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for inputs,ft_inputs, labels in dataloader:\n            inputs, ft_inputs, labels = inputs.to(device).float(),ft_inputs.to(device), labels.to(device)\n            outputs_cls = model(inputs)\n            \n            loss = criterion_cls(outputs_cls, labels)\n            running_loss += loss.item()\n            \n            preds = torch.argmax(outputs_cls, dim=1)\n            running_acc += (preds == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n    \n    avg_loss = running_loss / len(dataloader)\n    avg_acc = running_acc / len(dataloader.dataset)\n    precision = precision_score(all_labels, all_preds, average='weighted')\n    recall = recall_score(all_labels, all_preds, average='weighted')\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    \n    return avg_loss, avg_acc, precision, recall, f1\n\n\n# Training Loop with Checkpointing\ndef train_model(model, train_loader, val_loader, criterion_cls,criterion_ft, optimizer, device, num_epochs=10, checkpoint_path='checkpoint.pth'):\n    start_epoch = 0\n    best_loss = float('inf')\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n    \n    if os.path.exists(checkpoint_path):\n        model, optimizer, start_epoch, best_loss = load_checkpoint(model, optimizer, checkpoint_path, device)\n        print(f\"Resuming from epoch {start_epoch+1}\")\n\n    for epoch in range(start_epoch, num_epochs):\n        model.train()\n        running_loss = 0.0\n        running_acc = 0.0\n        all_labels = []\n        all_preds = []\n        \n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n        \n        for inputs,ft_inputs, labels in progress_bar:\n            inputs,ft_inputs, labels = inputs.to(device).float(), ft_inputs.to(device) , labels.to(device)\n            optimizer.zero_grad()\n            outputs_cls ,outputs_ft = model(inputs)\n            \n            loss_cls = criterion_cls(outputs_cls, labels)\n            loss_ft = criterion_ft(outputs_ft, ft_inputs)\n            loss = 0.5 * loss_cls + 0.5 * loss_ft\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            \n            preds = torch.argmax(outputs_cls, dim=1)\n            running_acc += (preds == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            \n            progress_bar.set_postfix({'loss': running_loss/len(train_loader), 'acc': running_acc/len(train_loader.dataset)})\n        \n        avg_loss = running_loss / len(train_loader)\n        avg_acc = running_acc / len(train_loader.dataset)\n        \n        precision = precision_score(all_labels, all_preds, average='weighted')\n        recall = recall_score(all_labels, all_preds, average='weighted')\n        f1 = f1_score(all_labels, all_preds, average='weighted')\n        \n        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n        \n        val_loss, val_acc, val_precision, val_recall, val_f1 = evaluate_model(model, val_loader, criterion_cls, device)\n        print(f'Validation - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1 Score: {val_f1:.4f}')\n        \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            save_checkpoint(model, optimizer, epoch, checkpoint_path, best_loss)\n            print(f\"Checkpoint saved at epoch {epoch+1} with loss {best_loss:.4f}\")\n\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:53:46.448917Z","iopub.execute_input":"2024-07-06T16:53:46.449309Z","iopub.status.idle":"2024-07-06T16:53:46.471605Z","shell.execute_reply.started":"2024-07-06T16:53:46.449278Z","shell.execute_reply":"2024-07-06T16:53:46.470738Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df['feature'][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model with checkpointing and learning rate scheduler\ntrain_model(model, dataloader_train, dataloader_val, criterion_cls,criterion_ft, optimizer, device, num_epochs=50, checkpoint_path='/kaggle/working/fas_mobilenetv2_v2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-06T17:45:01.672307Z","iopub.execute_input":"2024-07-06T17:45:01.672713Z","iopub.status.idle":"2024-07-06T17:45:07.098403Z","shell.execute_reply.started":"2024-07-06T17:45:01.672679Z","shell.execute_reply":"2024-07-06T17:45:07.097172Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Resuming from epoch 19\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/50:   4%|▍         | 2/50 [00:05<02:01,  2.53s/it, loss=8.25e-5, acc=0.04]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with checkpointing and learning rate scheduler\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/fas_mobilenetv2_v2.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 71\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion_cls, criterion_ft, optimizer, device, num_epochs, checkpoint_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs,ft_inputs, labels \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m     72\u001b[0m     inputs,ft_inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat(), ft_inputs\u001b[38;5;241m.\u001b[39mto(device) , labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     73\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[39], line 21\u001b[0m, in \u001b[0;36mFASDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;241m43\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Generate the FT picture of the sample\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m ft_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_FT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","Cell \u001b[0;32mIn[39], line 46\u001b[0m, in \u001b[0;36mFASDataset.generate_FT\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     44\u001b[0m minn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(fimg)):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m maxx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     47\u001b[0m         maxx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(fimg[i])\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m minn \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mmin\u001b[39m(fimg[i]):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}